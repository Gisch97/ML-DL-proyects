{"cells":[{"source":"# Course Notes\nUse this workspace to take notes, store code snippets, and build your own interactive cheatsheet!\n\n_Note that the data from the course is not yet added to this workspace. You will need to navigate to the course overview page, download any data you wish to use, and add it to the file browser._","metadata":{},"id":"7607bdb2-1707-4361-a984-1c443fe84370","cell_type":"markdown"},{"source":"import torch\nimport torch.nn as nn\n","metadata":{"executionTime":967,"lastSuccessfullyExecutedCode":"import torch\nimport torch.nn as nn\n"},"id":"7f26dd6a-20aa-4d19-8d3f-b8f64fba1821","cell_type":"code","execution_count":2,"outputs":[]},{"source":"# Basic Neural Network\n\nThis could also be done just with INPUT_LAYER // weight = torch.rand(#SIZE)","metadata":{},"cell_type":"markdown","id":"b8d993bd-92e8-4767-94f0-b6c4adc0befc"},{"source":"input_layer, weight_1, weight_2, weight_3 = torch.tensor([[ 0.0401, -0.9005,  0.0397, -0.0876]]), \\\ntorch.tensor([[-0.1094, -0.8285,  0.0416, -1.1222],\n        [ 0.3327, -0.0461,  1.4473, -0.8070],\n        [ 0.0681, -0.7058, -1.8017,  0.5857],\n        [ 0.8764,  0.9618, -0.4505,  0.2888]]),\\\n torch.tensor([[ 0.6856, -1.7650,  1.6375, -1.5759],\n        [-0.1092, -0.1620,  0.1951, -0.1169],\n        [-0.5120,  1.1997,  0.8483, -0.2476],\n        [-0.3369,  0.5617, -0.6658,  0.2221]]),\\\n torch.tensor([[ 0.8824,  0.1268,  1.1951,  1.3061],\n        [-0.8753, -0.3277, -0.1454, -0.0167],\n        [ 0.3582,  0.3254, -1.8509, -1.4205],\n        [ 0.3786,  0.5999, -0.5665, -0.3975]])","metadata":{"executionTime":0,"lastSuccessfullyExecutedCode":"input_layer, weight_1, weight_2, weight_3 = torch.tensor([[ 0.0401, -0.9005,  0.0397, -0.0876]]), \\\ntorch.tensor([[-0.1094, -0.8285,  0.0416, -1.1222],\n        [ 0.3327, -0.0461,  1.4473, -0.8070],\n        [ 0.0681, -0.7058, -1.8017,  0.5857],\n        [ 0.8764,  0.9618, -0.4505,  0.2888]]),\\\n torch.tensor([[ 0.6856, -1.7650,  1.6375, -1.5759],\n        [-0.1092, -0.1620,  0.1951, -0.1169],\n        [-0.5120,  1.1997,  0.8483, -0.2476],\n        [-0.3369,  0.5617, -0.6658,  0.2221]]),\\\n torch.tensor([[ 0.8824,  0.1268,  1.1951,  1.3061],\n        [-0.8753, -0.3277, -0.1454, -0.0167],\n        [ 0.3582,  0.3254, -1.8509, -1.4205],\n        [ 0.3786,  0.5999, -0.5665, -0.3975]])"},"cell_type":"code","id":"94648960-2183-4130-8d3c-ac5971ada24e","execution_count":3,"outputs":[]},{"source":"## Take Notes\n\nAdd notes here about the concepts you've learned and code cells with code you want to keep.","metadata":{},"id":"a0ac303b-ad44-4690-a9f0-a70619fcabc4","cell_type":"markdown"},{"source":"_Add your notes here_","metadata":{},"id":"540470d7-eb27-442b-b0d5-ab28b0a7da96","cell_type":"markdown"},{"source":"# Calculate the first and second hidden layer\nhidden_1 = torch.matmul(input_layer, weight_1)\nhidden_2 = torch.matmul(hidden_1, weight_2)\n\n# Calculate the output\nprint(torch.matmul(hidden_2, weight_3))\n\n# Calculate weight_composed_1 and weight\nweight_composed_1 = torch.matmul(weight_1, weight_2)\nweight = torch.matmul(weight_composed_1, weight_3)\n\n# Multiply input_layer with weight\nprint(torch.matmul(input_layer, weight))","metadata":{"executionTime":64,"lastSuccessfullyExecutedCode":"# Calculate the first and second hidden layer\nhidden_1 = torch.matmul(input_layer, weight_1)\nhidden_2 = torch.matmul(hidden_1, weight_2)\n\n# Calculate the output\nprint(torch.matmul(hidden_2, weight_3))\n\n# Calculate weight_composed_1 and weight\nweight_composed_1 = torch.matmul(weight_1, weight_2)\nweight = torch.matmul(weight_composed_1, weight_3)\n\n# Multiply input_layer with weight\nprint(torch.matmul(input_layer, weight))","outputsMetadata":{"0":{"height":57,"type":"stream"}}},"id":"7869e914-9bb1-4f2d-a48b-5ab87e36e9b7","cell_type":"code","execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":"tensor([[0.2653, 0.1311, 3.8219, 3.0032]])\ntensor([[0.2653, 0.1311, 3.8219, 3.0032]])\n"}]},{"source":"# Activation Function","metadata":{},"cell_type":"markdown","id":"cc40ffcb-2183-484f-ace1-ca588eed8891"},{"source":"# Instantiate non-linearity\nrelu = nn.ReLU()\n\n# Apply non-linearity on the hidden layers\nhidden_1_activated = relu(torch.matmul(input_layer, weight_1))\nhidden_2_activated = relu(torch.matmul(hidden_1_activated, weight_2))\nprint(torch.matmul(hidden_2_activated, weight_3))\n\n# Apply non-linearity in the product of first two weights. \nweight_composed_1_activated = relu(torch.matmul(weight_1, weight_2))\n\n# Multiply `weight_composed_1_activated` with `weight_3\nweight = torch.matmul(weight_composed_1_activated, weight_3)\n\n# Multiply input_layer with weight\nprint(torch.matmul(input_layer, weight))","metadata":{"executionTime":88,"lastSuccessfullyExecutedCode":"# Instantiate non-linearity\nrelu = nn.ReLU()\n\n# Apply non-linearity on the hidden layers\nhidden_1_activated = relu(torch.matmul(input_layer, weight_1))\nhidden_2_activated = relu(torch.matmul(hidden_1_activated, weight_2))\nprint(torch.matmul(hidden_2_activated, weight_3))\n\n# Apply non-linearity in the product of first two weights. \nweight_composed_1_activated = relu(torch.matmul(weight_1, weight_2))\n\n# Multiply `weight_composed_1_activated` with `weight_3\nweight = torch.matmul(weight_composed_1_activated, weight_3)\n\n# Multiply input_layer with weight\nprint(torch.matmul(input_layer, weight))","outputsMetadata":{"0":{"height":57,"type":"stream"}}},"cell_type":"code","id":"0e251f84-0e28-432d-a209-680f9623221b","execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":"tensor([[-0.2770, -0.0345, -0.1410, -0.0664]])\ntensor([[-0.2117, -0.4782,  4.0438,  3.0417]])\n"}]},{"source":"# Instantiate ReLU activation function as relu\nrelu = nn.ReLU()\n\n# Initialize weight_1 and weight_2 with random numbers\nweight_1 = torch.rand(4, 6)\nweight_2 = torch.rand(6, 2)\n\n# Multiply input_layer with weight_1\nhidden_1 = torch.matmul(input_layer, weight_1)\n\n# Apply ReLU activation function over hidden_1 and multiply with weight_2\nhidden_1_activated = relu(hidden_1)\nprint(torch.matmul(hidden_1_activated, weight_2))","metadata":{"executionTime":84,"lastSuccessfullyExecutedCode":"# Instantiate ReLU activation function as relu\nrelu = nn.ReLU()\n\n# Initialize weight_1 and weight_2 with random numbers\nweight_1 = torch.rand(4, 6)\nweight_2 = torch.rand(6, 2)\n\n# Multiply input_layer with weight_1\nhidden_1 = torch.matmul(input_layer, weight_1)\n\n# Apply ReLU activation function over hidden_1 and multiply with weight_2\nhidden_1_activated = relu(hidden_1)\nprint(torch.matmul(hidden_1_activated, weight_2))","outputsMetadata":{"0":{"height":37,"type":"stream"}}},"cell_type":"code","id":"034e0cc5-db42-4f42-863a-c331d6b9833c","execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":"tensor([[0., 0.]])\n"}]},{"source":"# Loss Function","metadata":{},"cell_type":"markdown","id":"253802b4-6f52-4b53-bf0a-4135990a02cc"},{"source":"# Initialize the scores and ground truth\nlogits = torch.tensor([[ -1.2, 0.12, 4.8]])\nground_truth = torch.tensor([2])\n\n# Instantiate cross entropy loss\ncriterion = nn.CrossEntropyLoss()\n\n# Compute and print the loss\nloss = criterion(logits, ground_truth)\nprint(loss)","metadata":{"executionTime":75,"lastSuccessfullyExecutedCode":"# Initialize the scores and ground truth\nlogits = torch.tensor([[ -1.2, 0.12, 4.8]])\nground_truth = torch.tensor([2])\n\n# Instantiate cross entropy loss\ncriterion = nn.CrossEntropyLoss()\n\n# Compute and print the loss\nloss = criterion(logits, ground_truth)\nprint(loss)","outputsMetadata":{"0":{"height":37,"type":"stream"}}},"cell_type":"code","id":"97428e93-10c6-4e34-9884-78dc0ff8ac7f","execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":"tensor(0.0117)\n"}]},{"source":"# Initialize logits and ground truth\nlogits = torch.rand(1,1000)\nground_truth = torch.tensor([111])\n\n# Instantiate cross-entropy loss\ncriterion = nn.CrossEntropyLoss()\n\n# Calculate and print the loss\nloss = criterion(logits, ground_truth)\nprint(loss)","metadata":{"executionTime":57,"lastSuccessfullyExecutedCode":"# Initialize logits and ground truth\nlogits = torch.rand(1,1000)\nground_truth = torch.tensor([111])\n\n# Instantiate cross-entropy loss\ncriterion = nn.CrossEntropyLoss()\n\n# Calculate and print the loss\nloss = criterion(logits, ground_truth)\nprint(loss)","outputsMetadata":{"0":{"height":37,"type":"stream"}}},"cell_type":"code","id":"a8587e74-84cc-47b0-bbfb-6b3b11b61597","execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":"tensor(6.9989)\n"}]},{"source":"# Preparing MNIST Dataset || Dataloader","metadata":{},"cell_type":"markdown","id":"f3124557-e704-4283-bad2-b54a3861226f"},{"source":"import torchvision\nimport torch.utils.data\nimport torchvision.transforms as transforms","metadata":{"executionTime":0,"lastSuccessfullyExecutedCode":"import torchvision\nimport torch.utils.data\nimport torchvision.transforms as transforms"},"cell_type":"code","id":"7c8669db-7be6-4c4c-ba06-a432d111beb7","execution_count":9,"outputs":[]},{"source":"# Transform the data to torch tensors and normalize it \ntransform = transforms.Compose([transforms.ToTensor(),\n\t\t\t\t\t\t\t\ttransforms.Normalize((0.1307), ((0.3081)))])\n\n# Prepare training set and testing set\ntrainset = torchvision.datasets.MNIST('mnist', train=True, \n\t\t\t\t\t\t\t\t\t  download=True, transform=transform)\ntestset = torchvision.datasets.MNIST('mnist', train=False, \n\t\t\t\t\t\t\t\t\t  download=True, transform=transform)\n\n# Prepare training loader and testing loader\ntrainloader = torch.utils.data.DataLoader(trainset, batch_size=32,\n                                          shuffle=True, num_workers=0)\ntestloader = torch.utils.data.DataLoader(testset, batch_size=32,\n                                          shuffle=False, num_workers=0) \n\n# Compute the shape of the training set and testing set\ntrainset_shape = trainloader.dataset.train_data.shape\ntestset_shape = testloader.dataset.test_data.shape\n# Print the computed shapes\nprint(trainset_shape, testset_shape)\n\n# Compute the size of the minibatch for training set and testing set\ntrainset_batchsize = trainloader.batch_size\ntestset_batchsize = testloader.batch_size\n\n# Print sizes of the minibatch\nprint(trainset_batchsize, testset_batchsize)","metadata":{"executionTime":117,"lastSuccessfullyExecutedCode":"# Transform the data to torch tensors and normalize it \ntransform = transforms.Compose([transforms.ToTensor(),\n\t\t\t\t\t\t\t\ttransforms.Normalize((0.1307), ((0.3081)))])\n\n# Prepare training set and testing set\ntrainset = torchvision.datasets.MNIST('mnist', train=True, \n\t\t\t\t\t\t\t\t\t  download=True, transform=transform)\ntestset = torchvision.datasets.MNIST('mnist', train=False, \n\t\t\t\t\t\t\t\t\t  download=True, transform=transform)\n\n# Prepare training loader and testing loader\ntrainloader = torch.utils.data.DataLoader(trainset, batch_size=32,\n                                          shuffle=True, num_workers=0)\ntestloader = torch.utils.data.DataLoader(testset, batch_size=32,\n                                          shuffle=False, num_workers=0) \n\n# Compute the shape of the training set and testing set\ntrainset_shape = trainloader.dataset.train_data.shape\ntestset_shape = testloader.dataset.test_data.shape\n# Print the computed shapes\nprint(trainset_shape, testset_shape)\n\n# Compute the size of the minibatch for training set and testing set\ntrainset_batchsize = trainloader.batch_size\ntestset_batchsize = testloader.batch_size\n\n# Print sizes of the minibatch\nprint(trainset_batchsize, testset_batchsize)","outputsMetadata":{"0":{"height":57,"type":"stream"}}},"cell_type":"code","id":"2da7ff8d-69f1-4a60-9612-449c58cbdd51","execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":"torch.Size([60000, 28, 28]) torch.Size([10000, 28, 28])\n32 32\n"}]},{"source":"# Train a Neural Network","metadata":{},"cell_type":"markdown","id":"6c6faf65-2418-4f89-84b9-4430a9095c08"},{"source":"import torch.nn.functional as F\nimport torch.optim as optim","metadata":{"executionTime":0,"lastSuccessfullyExecutedCode":"import torch.nn.functional as F\nimport torch.optim as optim"},"cell_type":"code","id":"4204f55b-ce53-4b47-aa5e-ae87f01ed23c","execution_count":11,"outputs":[]},{"source":"# Define the class Net\nclass Net(nn.Module):\n    def __init__(self):    \n    \t# Define all the parameters of the net\n        super(Net, self).__init__()\n        self.fc1 = nn.Linear(28 * 28 * 1, 200)\n        self.fc2 = nn.Linear(200, 10)\n\n    def forward(self, x):   \n    \t# Do the forward pass\n        x = F.relu(self.fc1(x))\n        x = self.fc2(x)\n        return x","metadata":{"executionTime":0,"lastSuccessfullyExecutedCode":"# Define the class Net\nclass Net(nn.Module):\n    def __init__(self):    \n    \t# Define all the parameters of the net\n        super(Net, self).__init__()\n        self.fc1 = nn.Linear(28 * 28 * 1, 200)\n        self.fc2 = nn.Linear(200, 10)\n\n    def forward(self, x):   \n    \t# Do the forward pass\n        x = F.relu(self.fc1(x))\n        x = self.fc2(x)\n        return x"},"cell_type":"code","id":"00430e45-1666-487a-974f-90c804b50c92","execution_count":12,"outputs":[]},{"source":"# Instantiate the Adam optimizer and Cross-Entropy loss function\nmodel = Net()   \noptimizer = optim.Adam(model.parameters(), lr=3e-4)\ncriterion = nn.CrossEntropyLoss()\n  \nfor batch_idx, data_target in enumerate(trainloader):\n    data = data_target[0]\n    target = data_target[1]\n    data = data.view(-1, 28 * 28)\n    optimizer.zero_grad()\n\n    # Complete a forward pass\n    output = model(data)\n\n    # Compute the loss, gradients and change the weights\n    loss = criterion(output,target)\n    loss.backward()\n    optimizer.step()","metadata":{"executionTime":63836,"lastSuccessfullyExecutedCode":"# Instantiate the Adam optimizer and Cross-Entropy loss function\nmodel = Net()   \noptimizer = optim.Adam(model.parameters(), lr=3e-4)\ncriterion = nn.CrossEntropyLoss()\n  \nfor batch_idx, data_target in enumerate(trainloader):\n    data = data_target[0]\n    target = data_target[1]\n    data = data.view(-1, 28 * 28)\n    optimizer.zero_grad()\n\n    # Complete a forward pass\n    output = model(data)\n\n    # Compute the loss, gradients and change the weights\n    loss = criterion(output,target)\n    loss.backward()\n    optimizer.step()"},"cell_type":"code","id":"6f1b7e65-b000-42d4-bdba-fd16b44dcf71","execution_count":13,"outputs":[]},{"source":"correct, total = 0, 0\n# Set the model in eval mode\nmodel.eval()\n\nfor i, data in enumerate(testloader, 0):\n    inputs, labels = data\n    \n    # Put each image into a vector\n    inputs = inputs.view(-1, 28 * 28)\n    \n    # Do the forward pass and get the predictions\n    outputs = model(inputs)\n    _, outputs = torch.max(outputs.data, 1)\n    total += labels.size(0)\n    correct += (outputs == labels).sum().item()\nprint('The testing set accuracy of the network is: %d %%' % (100 * correct / total))","metadata":{"executionTime":8770,"lastSuccessfullyExecutedCode":"correct, total = 0, 0\n# Set the model in eval mode\nmodel.eval()\n\nfor i, data in enumerate(testloader, 0):\n    inputs, labels = data\n    \n    # Put each image into a vector\n    inputs = inputs.view(-1, 28 * 28)\n    \n    # Do the forward pass and get the predictions\n    outputs = model(inputs)\n    _, outputs = torch.max(outputs.data, 1)\n    total += labels.size(0)\n    correct += (outputs == labels).sum().item()\nprint('The testing set accuracy of the network is: %d %%' % (100 * correct / total))","outputsMetadata":{"0":{"height":37,"type":"stream"}}},"cell_type":"code","id":"9dd2873c-1a99-4ea7-aff2-201b07556c96","execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":"The testing set accuracy of the network is: 95 %\n"}]},{"source":"# CNN on this set","metadata":{},"cell_type":"markdown","id":"9f00d6d6-5f79-4712-ad36-e11318b15034"},{"source":"# Create 10 random images of shape (1, 28, 28)\nimages = torch.rand(10, 1, 28, 28)\n\nim = torch.Tensor([[[[ 8.,  1.,  2.,  5.,  3.,  1.],\n          [ 6.,  0.,  0., -5.,  7.,  9.],\n          [ 1.,  9., -1., -2.,  2.,  6.],\n          [ 0.,  4.,  2., -3.,  4.,  3.],\n          [ 2., -1.,  4., -1., -2.,  3.],\n          [ 2., -4.,  5.,  9., -7.,  8.]]]])","metadata":{"executionTime":22,"lastSuccessfullyExecutedCode":"# Create 10 random images of shape (1, 28, 28)\nimages = torch.rand(10, 1, 28, 28)\n\nim = torch.Tensor([[[[ 8.,  1.,  2.,  5.,  3.,  1.],\n          [ 6.,  0.,  0., -5.,  7.,  9.],\n          [ 1.,  9., -1., -2.,  2.,  6.],\n          [ 0.,  4.,  2., -3.,  4.,  3.],\n          [ 2., -1.,  4., -1., -2.,  3.],\n          [ 2., -4.,  5.,  9., -7.,  8.]]]])"},"cell_type":"code","id":"0900758b-f446-45d9-ac5a-a24e9f4f3978","execution_count":15,"outputs":[]},{"source":"## OOP","metadata":{},"cell_type":"markdown","id":"89fb8c91-dac8-481b-a2c2-00578fb45523"},{"source":"# OOP\n\n# Build 6 conv. filters\nconv_filters = torch.nn.Conv2d(in_channels=1, out_channels=6, kernel_size=3, stride=1, padding=1)\n\n# Convolve the image with the filters \noutput_feature = conv_filters(images)\nprint(output_feature.shape)\n\n## MAX POOLING\n\n# Build a pooling operator with size `2`.\nmax_pooling = torch.nn.MaxPool2d(2)\n\n# Apply the pooling operator\noutput_feature = max_pooling(im)\n\nprint(output_feature)\n\n## AVG POOLING\n\n# Build a pooling operator with size `2`.\navg_pooling = torch.nn.AvgPool2d(2)\n\n# Apply the pooling operator\noutput_feature = avg_pooling(im)\nprint(output_feature)","metadata":{"executionTime":71,"lastSuccessfullyExecutedCode":"# OOP\n\n# Build 6 conv. filters\nconv_filters = torch.nn.Conv2d(in_channels=1, out_channels=6, kernel_size=3, stride=1, padding=1)\n\n# Convolve the image with the filters \noutput_feature = conv_filters(images)\nprint(output_feature.shape)\n\n## MAX POOLING\n\n# Build a pooling operator with size `2`.\nmax_pooling = torch.nn.MaxPool2d(2)\n\n# Apply the pooling operator\noutput_feature = max_pooling(im)\n\nprint(output_feature)\n\n## AVG POOLING\n\n# Build a pooling operator with size `2`.\navg_pooling = torch.nn.AvgPool2d(2)\n\n# Apply the pooling operator\noutput_feature = avg_pooling(im)\nprint(output_feature)","outputsMetadata":{"0":{"height":157,"type":"stream"}}},"cell_type":"code","id":"1606d8ac-2abb-45cb-949f-e90f5edaeda1","execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":"torch.Size([10, 6, 28, 28])\ntensor([[[[8., 5., 9.],\n          [9., 2., 6.],\n          [2., 9., 8.]]]])\ntensor([[[[ 3.7500,  0.5000,  5.0000],\n          [ 3.5000, -1.0000,  3.7500],\n          [-0.2500,  4.2500,  0.5000]]]])\n"}]},{"source":"## Function","metadata":{},"cell_type":"markdown","id":"4e222f50-08fe-491e-9fb8-647eb3e7538c"},{"source":"# Function \nimport torch.nn.functional as F\n\n# Create 6 filters\nfilters = torch.rand(6, 1, 3, 3)\n\n# Convolve the image with the filters\noutput_feature = F.conv2d(images, filters, stride=1, padding=1)\nprint(output_feature.shape)\n\n## MAX POOLING\n\n# Use pooling operator in the image\noutput_feature_F = F.max_pool2d(im, 2)\n\nprint(output_feature_F)\n\n## AVG POOLING\n\n# Use pooling operator in the image\noutput_feature_F = F.avg_pool2d(im,2)\n\nprint(output_feature_F)","metadata":{"executionTime":25,"lastSuccessfullyExecutedCode":"# Function \nimport torch.nn.functional as F\n\n# Create 6 filters\nfilters = torch.rand(6, 1, 3, 3)\n\n# Convolve the image with the filters\noutput_feature = F.conv2d(images, filters, stride=1, padding=1)\nprint(output_feature.shape)\n\n## MAX POOLING\n\n# Use pooling operator in the image\noutput_feature_F = F.max_pool2d(im, 2)\n\nprint(output_feature_F)\n\n## AVG POOLING\n\n# Use pooling operator in the image\noutput_feature_F = F.avg_pool2d(im,2)\n\nprint(output_feature_F)","outputsMetadata":{"0":{"height":157,"type":"stream"}}},"cell_type":"code","id":"8d66cdb1-aa2b-497c-8fb9-0eb1c2f5d73c","execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":"torch.Size([10, 6, 28, 28])\ntensor([[[[8., 5., 9.],\n          [9., 2., 6.],\n          [2., 9., 8.]]]])\ntensor([[[[ 3.7500,  0.5000,  5.0000],\n          [ 3.5000, -1.0000,  3.7500],\n          [-0.2500,  4.2500,  0.5000]]]])\n"}]},{"source":"# Convolutional NN","metadata":{},"cell_type":"markdown","id":"66bb4220-a2eb-40a6-b97e-29b17ad8184d"},{"source":"class Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        \n        # Instantiate two convolutional layers\n        self.conv1 = nn.Conv2d(in_channels=1, out_channels=5, kernel_size=3, padding=1)\n        self.conv2 = nn.Conv2d(in_channels=5, out_channels=10, kernel_size=3, padding=1)\n        \n        # Instantiate the ReLU nonlinearity\n        self.relu = nn.ReLU()\n        \n        # Instantiate a max pooling layer\n        self.pool = nn.MaxPool2d(2, 2)\n        \n        # Instantiate a fully connected layer\n        self.fc = nn.Linear(7 * 7 * 10, 10)\n        \n    def forward(self, x):\n\n        # Apply conv followd by relu, then in next line pool\n        x = self.relu(self.conv1(x))\n        x = self.pool(x)\n\n        # Apply conv followd by relu, then in next line pool\n        x = self.relu(self.conv2(x))\n        x = self.relu(self.pool(x))\n\n        # Prepare the image for the fully connected layer\n        x = x.view(-1, 7 * 7 * 10)\n\n        # Apply the fully connected layer and return the result\n        return self.fc(x)","metadata":{"executionTime":31,"lastSuccessfullyExecutedCode":"class Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        \n        # Instantiate two convolutional layers\n        self.conv1 = nn.Conv2d(in_channels=1, out_channels=5, kernel_size=3, padding=1)\n        self.conv2 = nn.Conv2d(in_channels=5, out_channels=10, kernel_size=3, padding=1)\n        \n        # Instantiate the ReLU nonlinearity\n        self.relu = nn.ReLU()\n        \n        # Instantiate a max pooling layer\n        self.pool = nn.MaxPool2d(2, 2)\n        \n        # Instantiate a fully connected layer\n        self.fc = nn.Linear(7 * 7 * 10, 10)\n        \n    def forward(self, x):\n\n        # Apply conv followd by relu, then in next line pool\n        x = self.relu(self.conv1(x))\n        x = self.pool(x)\n\n        # Apply conv followd by relu, then in next line pool\n        x = self.relu(self.conv2(x))\n        x = self.relu(self.pool(x))\n\n        # Prepare the image for the fully connected layer\n        x = x.view(-1, 7 * 7 * 10)\n\n        # Apply the fully connected layer and return the result\n        return self.fc(x)"},"cell_type":"code","id":"5546bf1f-2690-4c52-8d46-e4a22755d116","execution_count":18,"outputs":[]},{"source":"CNN = Net()\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(CNN.parameters(), lr=3e-4)\nfor i, data in enumerate(trainloader, 0):\n    inputs, labels = data\n    optimizer.zero_grad()\n\n    # Compute the forward pass\n    outputs = CNN(inputs)\n        \n    # Compute the loss function\n    loss = criterion(outputs, labels)\n        \n    # Compute the gradients\n    loss.backward()\n    \n    # Update the weights\n    optimizer.step()","metadata":{"executionTime":75115,"lastSuccessfullyExecutedCode":"CNN = Net()\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(CNN.parameters(), lr=3e-4)\nfor i, data in enumerate(trainloader, 0):\n    inputs, labels = data\n    optimizer.zero_grad()\n\n    # Compute the forward pass\n    outputs = CNN(inputs)\n        \n    # Compute the loss function\n    loss = criterion(outputs, labels)\n        \n    # Compute the gradients\n    loss.backward()\n    \n    # Update the weights\n    optimizer.step()"},"cell_type":"code","id":"62b85e47-e66b-4c5e-8630-79eee6a3bbc2","execution_count":19,"outputs":[]},{"source":"#correct, total = 0, 0\n#predicted = []\n#CNN.eval()\n# Iterate over the data in the test_loader\n#for i, data in enumerate(testloader, 0):\n  \n    # Get the image and label from data\n    #image, label = data\n    \n    # Make a forward pass in the net with your image\n    #output = CNN(image)\n    \n    # Argmax the results of the net\n    #_ , predicted = torch.max(output.data, 1)\n    \n    #total += label.size(0)\n    #correct += (predicted == labels).sum().item()\n    \n    #if predicted == label:\n    #   print(\"Yipes, your net made the right prediction \" + str(predicted))\n    #else:\n    #    print(\"Your net prediction was \" + str(predicted) + \", but the correct label is: \" + str(label))","metadata":{"executionTime":0,"lastSuccessfullyExecutedCode":"#correct, total = 0, 0\n#predicted = []\n#CNN.eval()\n# Iterate over the data in the test_loader\n#for i, data in enumerate(testloader, 0):\n  \n    # Get the image and label from data\n    #image, label = data\n    \n    # Make a forward pass in the net with your image\n    #output = CNN(image)\n    \n    # Argmax the results of the net\n    #_ , predicted = torch.max(output.data, 1)\n    \n    #total += label.size(0)\n    #correct += (predicted == labels).sum().item()\n    \n    #if predicted == label:\n    #   print(\"Yipes, your net made the right prediction \" + str(predicted))\n    #else:\n    #    print(\"Your net prediction was \" + str(predicted) + \", but the correct label is: \" + str(label))"},"cell_type":"code","id":"b0faf79a-4ed9-4fe7-a7f7-8d1d07786a2a","execution_count":20,"outputs":[]},{"source":"# Sequential CNN","metadata":{},"cell_type":"markdown","id":"44b32e7c-5ab8-4c60-b579-674ac1ac54a5"},{"source":"class Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        \n        # Declare all the layers for feature extraction\n        self.features = nn.Sequential(nn.Conv2d(in_channels=1, out_channels=5, kernel_size=3, padding=1), \n                                      nn.ReLU(inplace=True),\n                                      nn.Conv2d(in_channels=5, out_channels=10, kernel_size=3, padding=1), \n                                      nn.MaxPool2d(2, 2), nn.ReLU(inplace=True),\n                                      nn.Conv2d(in_channels=10, out_channels=20, kernel_size=3, padding=1), \n                                      nn.ReLU(inplace=True),\n                                      nn.Conv2d(in_channels=20, out_channels=40, kernel_size=3, padding=1), \n                                      nn.MaxPool2d(2, 2), nn.ReLU(inplace=True))\n# Declare all the layers for classification\n        self.classifier = nn.Sequential(nn.Linear(7 * 7 * 40, 1024), nn.ReLU(inplace=True),\n                                       \tnn.Linear(1024, 2048), nn.ReLU(inplace=True),\n                                        nn.Linear(2048, 10))\n            \n    def forward(self, x):\n      \n        # Apply the feature extractor in the input\n        x = self.features(x)\n        \n        # Squeeze the three spatial dimensions in one\n        x = x.view(-1, 7 * 7 * 40)\n        \n        # Classify the images\n        x = self.classifier(x)\n        return x","metadata":{"executionTime":97,"lastSuccessfullyExecutedCode":"class Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        \n        # Declare all the layers for feature extraction\n        self.features = nn.Sequential(nn.Conv2d(in_channels=1, out_channels=5, kernel_size=3, padding=1), \n                                      nn.ReLU(inplace=True),\n                                      nn.Conv2d(in_channels=5, out_channels=10, kernel_size=3, padding=1), \n                                      nn.MaxPool2d(2, 2), nn.ReLU(inplace=True),\n                                      nn.Conv2d(in_channels=10, out_channels=20, kernel_size=3, padding=1), \n                                      nn.ReLU(inplace=True),\n                                      nn.Conv2d(in_channels=20, out_channels=40, kernel_size=3, padding=1), \n                                      nn.MaxPool2d(2, 2), nn.ReLU(inplace=True))\n# Declare all the layers for classification\n        self.classifier = nn.Sequential(nn.Linear(7 * 7 * 40, 1024), nn.ReLU(inplace=True),\n                                       \tnn.Linear(1024, 2048), nn.ReLU(inplace=True),\n                                        nn.Linear(2048, 10))\n            \n    def forward(self, x):\n      \n        # Apply the feature extractor in the input\n        x = self.features(x)\n        \n        # Squeeze the three spatial dimensions in one\n        x = x.view(-1, 7 * 7 * 40)\n        \n        # Classify the images\n        x = self.classifier(x)\n        return x"},"cell_type":"code","id":"68f35516-0463-45cf-ba23-5deda5d3c790","execution_count":21,"outputs":[]},{"source":"# Preventing overfitting : validation set","metadata":{},"cell_type":"markdown","id":"2bdbe725-0933-4420-b191-1c9ca071f895"},{"source":"import numpy as np\n# Shuffle the indices\nindices = np.arange(60000)\nnp.random.shuffle(indices)\n\n\n# Build the train loader\ntrain_loader = torch.utils.data.DataLoader(torchvision.datasets.MNIST('mnist', download=True, train=True,\n                     transform=transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])),\n                     batch_size=64, shuffle=False, sampler=torch.utils.data.SubsetRandomSampler(indices[:55000]))\n\n# Build the validation loader\n\nval_loader = torch.utils.data.DataLoader(torchvision.datasets.MNIST('mnist', download=True, train=True,\n                   transform=transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])),\n                   batch_size=64, shuffle=False, sampler=torch.utils.data.SubsetRandomSampler(indices[55000:60000]))\n\n","metadata":{"executionTime":0,"lastSuccessfullyExecutedCode":"import numpy as np\n# Shuffle the indices\nindices = np.arange(60000)\nnp.random.shuffle(indices)\n\n\n# Build the train loader\ntrain_loader = torch.utils.data.DataLoader(torchvision.datasets.MNIST('mnist', download=True, train=True,\n                     transform=transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])),\n                     batch_size=64, shuffle=False, sampler=torch.utils.data.SubsetRandomSampler(indices[:55000]))\n\n# Build the validation loader\n\nval_loader = torch.utils.data.DataLoader(torchvision.datasets.MNIST('mnist', download=True, train=True,\n                   transform=transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])),\n                   batch_size=64, shuffle=False, sampler=torch.utils.data.SubsetRandomSampler(indices[55000:60000]))\n\n"},"cell_type":"code","id":"8d1a8d22-4ba2-4ec2-b537-8dba49b51db2","execution_count":22,"outputs":[]},{"source":"# Preventing overfitting: L2 / ","metadata":{},"cell_type":"markdown","id":"bf78e323-2e34-46bf-bf6f-7ff18fd7a27a"},{"source":"# Instantiate the network\nmodel = Net()\n\n# Instantiate the cross-entropy loss\ncriterion = nn.CrossEntropyLoss()\n\n# Instantiate the Adam optimizer\noptimizer = optim.Adam(model.parameters(), lr=3e-4, weight_decay=0.001)\n\nclass Net(nn.Module):\n    def __init__(self):\n        \n        # Define all the parameters of the net\n        self.classifier = nn.Sequential(\n            nn.Linear(28*28, 200),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=0.5),\n            nn.Linear(200, 500),\n            nn.ReLU(inplace=True),\n            nn.Linear(500, 10))\n        \n    def forward(self, x):\n    \n    \t# Do the forward pass\n        return self.classifier(x)\n    ","metadata":{"executionTime":41,"lastSuccessfullyExecutedCode":"# Instantiate the network\nmodel = Net()\n\n# Instantiate the cross-entropy loss\ncriterion = nn.CrossEntropyLoss()\n\n# Instantiate the Adam optimizer\noptimizer = optim.Adam(model.parameters(), lr=3e-4, weight_decay=0.001)\n\nclass Net(nn.Module):\n    def __init__(self):\n        \n        # Define all the parameters of the net\n        self.classifier = nn.Sequential(\n            nn.Linear(28*28, 200),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=0.5),\n            nn.Linear(200, 500),\n            nn.ReLU(inplace=True),\n            nn.Linear(500, 10))\n        \n    def forward(self, x):\n    \n    \t# Do the forward pass\n        return self.classifier(x)\n    "},"cell_type":"code","id":"53327b3f-11cc-4d50-8155-cec003293b15","execution_count":23,"outputs":[]},{"source":"class Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        \n        # Implement the sequential module for feature extraction\n        self.features = nn.Sequential(\n            nn.Conv2d(in_channels=1, out_channels=10, kernel_size=3, stride=1, padding=1),\n            nn.MaxPool2d(2, 2), nn.ReLU(inplace=True), nn.BatchNorm2d(10),\n            nn.Conv2d(in_channels=10, out_channels=20, kernel_size=3, stride=1, padding=1),\n            nn.MaxPool2d(2, 2), nn.ReLU(inplace=True), nn.BatchNorm2d(20))\n        \n        # Implement the fully connected layer for classification\n        self.fc = nn.Linear(in_features=7*7*20, out_features=10)","metadata":{"executionTime":0,"lastSuccessfullyExecutedCode":"class Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        \n        # Implement the sequential module for feature extraction\n        self.features = nn.Sequential(\n            nn.Conv2d(in_channels=1, out_channels=10, kernel_size=3, stride=1, padding=1),\n            nn.MaxPool2d(2, 2), nn.ReLU(inplace=True), nn.BatchNorm2d(10),\n            nn.Conv2d(in_channels=10, out_channels=20, kernel_size=3, stride=1, padding=1),\n            nn.MaxPool2d(2, 2), nn.ReLU(inplace=True), nn.BatchNorm2d(20))\n        \n        # Implement the fully connected layer for classification\n        self.fc = nn.Linear(in_features=7*7*20, out_features=10)"},"cell_type":"code","id":"815098b1-4e20-4f82-921b-80a0e3a16375","execution_count":24,"outputs":[]}],"metadata":{"colab":{"name":"Welcome to DataCamp Workspaces.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.8.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"editor":"DataCamp Workspace"},"nbformat":4,"nbformat_minor":5}