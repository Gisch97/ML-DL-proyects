{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorization\n",
    "Vectorization improves the time used in the computation of mathematical operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "a = np.array([1,2,3,4])\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "249922.27093090024\n",
      "Vectorized version: 14.077901840209961 ms\n",
      "249922.2709309095\n",
      "For Loop version: 1202.0714282989502 ms\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "a = np.random.rand(1000000)\n",
    "b = np.random.rand(1000000)\n",
    "\n",
    "\n",
    "tic = time.time()\n",
    "c = np.dot(a,b)\n",
    "toc = time.time()\n",
    "\n",
    "print(c)\n",
    "print(\"Vectorized version: \"+ str(1000*(toc-tic))+\" ms\")\n",
    "\n",
    "c = 0\n",
    "tic = time.time()\n",
    "for i in range(1000000):\n",
    "    c+=a[i]*b[i]\n",
    "toc = time.time()\n",
    "print(c)\n",
    "print(\"For Loop version: \"+ str(1000*(toc-tic))+\" ms\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets vectorize the following example:\n",
    "$$\n",
    "u = Av \\\\\n",
    "u_i = \\sum_j  A_{ij}v_j\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 3]\n"
     ]
    }
   ],
   "source": [
    "A = np.array([[1,7,3],\n",
    "              [1,8,3]])\n",
    "v = np.array([2,2,-5])\n",
    "u = np.dot(A,v)\n",
    "print(u)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets apply the exponential to a vector:\n",
    "\n",
    "$$\n",
    "v = \\begin{bmatrix}\n",
    "v_1 \\\\\n",
    "v_2 \\\\\n",
    "\\vdots \\\\\n",
    "v_n \\\\\n",
    "\\end{bmatrix} =>\n",
    "e^v = \\begin{bmatrix}\n",
    "e^{v_1} \\\\\n",
    "e^{v_2} \\\\\n",
    "\\vdots \\\\\n",
    "e^{v_n} \\\\\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7.3890561e+00]\n",
      " [7.3890561e+00]\n",
      " [6.7379470e-03]]\n",
      "Vectorized version: 0.5767345428466797 ms\n",
      "[7.3890561e+00 7.3890561e+00 6.7379470e-03]\n",
      "For Loop version: 0.1125335693359375 ms\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "v = np.array([2,2,-5])\n",
    "\n",
    "tic = time.time()\n",
    "u = np.zeros((3,1))\n",
    "for i in range(3):\n",
    "    u[i] = math.exp(v[i])\n",
    "\n",
    "toc = time.time()\n",
    "\n",
    "print(u)\n",
    "print(\"Vectorized version: \"+ str(1000*(toc-tic))+\" ms\")\n",
    "\n",
    "\n",
    "u = np.zeros((3,1))\n",
    "tic = time.time()\n",
    "u = np.exp(v)\n",
    "toc = time.time()\n",
    "print(u)\n",
    "print(\"For Loop version: \"+ str(1000*(toc-tic))+\" ms\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other example:\n",
    "\n",
    "$$\n",
    "\\begin{array}{c|cccc}\n",
    "    & \\text{Apples} & \\text{Beef} & \\text{Eggs} & \\text{Potatoes} \\\\ \\hline\n",
    "\\text{Carb} & 56.0 & 0.0 & 4.4 & 68.0 \\\\\n",
    "\\text{Protein} & 1.2 & 104.0 & 52.0 & 8.0 \\\\\n",
    "\\text{Fat} & 1.8 & 135.0 & 99.0 & 0.9\n",
    "\\end{array}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 56.    0.    4.4  68. ]\n",
      " [  1.2 104.   52.    8. ]\n",
      " [  1.8 135.   99.    0.9]]\n"
     ]
    }
   ],
   "source": [
    "A = np.array([[56.0, 0.0, 4.4, 68.0],\n",
    "                [1.2, 104.0, 52.0, 8.0],\n",
    "                [1.8, 135.0, 99.0, 0.9]])\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 59.  239.  155.4  76.9]\n"
     ]
    }
   ],
   "source": [
    "cal = A.sum(axis=0)\n",
    "print(cal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[94.91525424  0.          2.83140283 88.42652796]\n",
      " [ 2.03389831 43.51464435 33.46203346 10.40312094]\n",
      " [ 3.05084746 56.48535565 63.70656371  1.17035111]]\n"
     ]
    }
   ],
   "source": [
    "percentage = 100 * A / cal.reshape(1,4)\n",
    "print(percentage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Descent implementation\n",
    "\n",
    "$ J \\equiv \\frac{1}{m} \\sum L(a,y) \\\\\n",
    "W \\in \\mathcal{R}^{n_x,m} \\\\\n",
    "b \\in \\mathcal{R} \\\\\n",
    "X \\in \\mathcal{R}^{n_x , m}.$\n",
    "\n",
    "$L = - (y log(a) + (1-y) log(1-a))$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression:\n",
    "\n",
    "$$\n",
    "\\left\\{\\begin{matrix}\n",
    "z^{(1)} = w^T x*{(1)} + b & & z^{(2)} = w^T x*{(2)} + b & & z^{(3)} = w^T x*{(3)} + b \\\\\n",
    "a^{(1)} = \\sigma (z^{(1)})& & a^{(2)} = \\sigma (z^{(2)})& & a^{(3)} = \\sigma (z^{(3)})\\\\ \n",
    "\\end{matrix}\\right.\n",
    "$$\n",
    "\n",
    "where\n",
    "$$\n",
    "\\begin{matrix}\n",
    "[z^{(1)} & z^{(2)} & \\dots & z^{(m)}] & = &  w^T X + [b,b, \\dots ,b] & = & w^T x^{(1)} + b + &\\dots&  + w^T x^{(m)} + b\n",
    "\\end{matrix}\n",
    "$$\n",
    "this may be `z = np.dot(w.T ,X) + b` and `a=np.sigmoid(z)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic regression with for loop\n",
    "\n",
    "# J = 0, dw1 = 0,dw2 = 0, db = 0\n",
    "# for i in range(1,m):\n",
    "    # z[i] = w.T*x[i] +b\n",
    "    # a[i] = np.sigmoid(z[i])\n",
    "    # J+= - [ y[i] * np.log(a[i]) + (1-y[i]) * np.log(1-a[i])]\n",
    "    # \n",
    "    # dz[i] = a[i] - y[i]\n",
    "    # dw1[i] = x1[i]*dz[i]\n",
    "    # dw2[i] = x2[i]*dz[i]\n",
    "    # db += dz[i]\n",
    "# J = J/m\n",
    "# dw1 = dw1/m\n",
    "# dw2 = dw2/m\n",
    "# db = db/m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = np.dot(w.T,x) + b\n",
    "A = np.sigmoid(Z)\n",
    "dZ = A -Y\n",
    "dw = 1/m * X * dZ.T\n",
    "db = 1/m * np.sum(dZ)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "enviroment1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
